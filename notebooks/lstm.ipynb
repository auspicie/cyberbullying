{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thayeylolu/cyberbullying/blob/lstm/notebooks/lstm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchtext==0.10.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dOBOcMHOOEK2",
        "outputId": "fc192212-8aec-478f-c89d-2fa8bb7c370e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torchtext==0.10.0\n",
            "  Downloading torchtext-0.10.0-cp37-cp37m-manylinux1_x86_64.whl (7.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.6 MB 15.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchtext==0.10.0) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchtext==0.10.0) (1.21.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torchtext==0.10.0) (4.64.1)\n",
            "Collecting torch==1.9.0\n",
            "  Downloading torch-1.9.0-cp37-cp37m-manylinux1_x86_64.whl (831.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 831.4 MB 2.8 kB/s \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence"
      ],
      "metadata": {
        "id": "TYXp5rhNNbkq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "from torch import nn, save, load\n",
        "from torch.optim import Adam\n",
        "# from torchtext.legacy import data\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "zKnXxK0ONbil"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# importing libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import re\n",
        "import warnings\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "warnings.filterwarnings(action=\"ignore\")\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "GDfE5LaCNbgj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "\n",
        "# nlp library of Pytorch\n",
        "from torchtext.legacy import data\n",
        "\n",
        "import warnings as wrn\n",
        "wrn.filterwarnings('ignore')"
      ],
      "metadata": {
        "trusted": true,
        "id": "xGH_DR1WLnR9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "outputId": "caf647cb-53e3-4767-eda4-7ff6a28b785c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-f0b9433756d2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# nlp library of Pytorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwarnings\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mwrn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torchtext.legacy'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SEED = 2021\n",
        "\n",
        "torch.manual_seed(SEED)\n",
        "torch.backends.cuda.deterministic = True"
      ],
      "metadata": {
        "trusted": true,
        "id": "7YWKU1BrLnR-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preprocessing\n",
        "Pytorch offers a good way of preprocessing text data: **torchtext**. Altough it seems like not stable and hard-to-use for newbies, it has nice features and it's easy to use.\n",
        "\n"
      ],
      "metadata": {
        "id": "RHj5JfJkLnR-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "trusted": true,
        "id": "JG11WGXvLnR-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def encode_label(label):\n",
        "    if label == 'not_cyberbullying':\n",
        "        return 0\n",
        "    elif label == 'gender':\n",
        "        return 1\n",
        "    elif label == 'religion':\n",
        "        return 2\n",
        "    elif label == 'other_cyberbullying':\n",
        "        return 3\n",
        "    elif label == 'age':\n",
        "        return 4\n",
        "    else:\n",
        "      return 5"
      ],
      "metadata": {
        "id": "BSpWrgMlMB3o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "url = \"/content/drive/MyDrive/NLP/train_data.csv\"\n",
        "# url = \"train_data.csv\"\n"
      ],
      "metadata": {
        "id": "GL_vdQ3aRpct"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(url)\n",
        "df= df.dropna()\n",
        "df['clean_txt_emoji'] = df['clean_txt_emoji'].str.replace('\\d+', '')\n",
        "\n",
        "df['clean_txt_emoji'].sample(3)\n",
        "df['clean_txt_emoji'] = df['clean_txt_emoji'].str.lower()\n",
        "df['label'] = df['cyberbullying_type'].apply(encode_label)\n",
        "df = df[['label', 'clean_txt_emoji']]\n",
        "\n",
        "train, test_valid = train_test_split(df,train_size= 0.70, random_state= 3040)\n",
        "test, valid = train_test_split(test_valid,train_size= .50, random_state= 3040)\n",
        "test['label'].value_counts()\n",
        "\n",
        "X_train, Y_train = train['clean_txt_emoji'].to_list(), train['label'].to_list()\n",
        "X_test, Y_test = test['clean_txt_emoji'].to_list(), test['label'].to_list()\n",
        "X_valid, Y_valid = valid['clean_txt_emoji'].to_list(), valid['label'].to_list()\n",
        "\n",
        "train_dat =list(zip(Y_train,X_train))\n",
        "valid_dat =list(zip(Y_valid,X_valid))\n",
        "test_dat=list(zip(Y_test,X_test))"
      ],
      "metadata": {
        "trusted": true,
        "id": "iTVkzHb0LnR-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Field is a normal column \n",
        "# LabelField is the label column.\n",
        "\n",
        "TEXT = data.Field(tokenize='spacy',batch_first=True,include_lengths=True)\n",
        "LABEL = data.LabelField(dtype = torch.float,batch_first=True)"
      ],
      "metadata": {
        "trusted": true,
        "id": "-sxnqCMZLnR-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fields = [('clean_txt_emoji',TEXT),(\"cyberbullying_type\",LABEL)]"
      ],
      "metadata": {
        "trusted": true,
        "id": "FX96EDGgLnR_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_data = data.TabularDataset(path=url,\n",
        "                                    format=\"csv\",\n",
        "                                    fields=fields,\n",
        "                                    skip_header=True\n",
        "                                   )\n",
        "\n",
        "print(vars(training_data.examples[0]))"
      ],
      "metadata": {
        "trusted": true,
        "id": "XH0FKCf8LnR_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "# train and validation splitting\n",
        "train_data,valid_data = training_data.split(split_ratio=0.75,\n",
        "                                            random_state=random.seed(SEED))\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "hvt-bNSbLnR_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Building vocabularies => (Token to integer)\n",
        "TEXT.build_vocab(train_data,\n",
        "                 min_freq=5)\n",
        "\n",
        "LABEL.build_vocab(train_data)"
      ],
      "metadata": {
        "trusted": true,
        "id": "lZE0sxYvLnR_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Size of text vocab:\",len(TEXT.vocab))"
      ],
      "metadata": {
        "trusted": true,
        "id": "MWxszxS4LnSA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Size of label vocab:\",len(LABEL.vocab))"
      ],
      "metadata": {
        "trusted": true,
        "id": "XMsKy8A9LnSA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TEXT.vocab.freqs.most_common(10)"
      ],
      "metadata": {
        "trusted": true,
        "id": "tBEDEwqNLnSA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating GPU variable\n",
        "device = torch.device(\"cuda\")\n",
        "\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "# We'll create iterators to get batches of data when we want to use them\n",
        "\"\"\"\n",
        "This BucketIterator batches the similar length of samples and reduces the need of \n",
        "padding tokens. This makes our future model more stable\n",
        "\n",
        "\"\"\"\n",
        "train_iterator,validation_iterator = data.BucketIterator.splits(\n",
        "    (train_data,valid_data),\n",
        "    batch_size = BATCH_SIZE,\n",
        "    # Sort key is how to sort the samples\n",
        "    sort_key = lambda x:len(x.text),\n",
        "    sort_within_batch = True,\n",
        "    device = device\n",
        ")"
      ],
      "metadata": {
        "trusted": true,
        "id": "cCq9whLKLnSA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RNN Network\n",
        "Now we'll use Pytorch to build an LSTM network in order to classify sms messages spam or not."
      ],
      "metadata": {
        "id": "NilWLdESLnSA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pytorch's nn module has lots of useful feature\n",
        "import torch.nn as nn\n",
        "\n",
        "class LSTMNet(nn.Module):\n",
        "    \n",
        "    def __init__(self,vocab_size,embedding_dim,hidden_dim,output_dim,n_layers,bidirectional,dropout):\n",
        "        \n",
        "        super(LSTMNet,self).__init__()\n",
        "        \n",
        "        # Embedding layer converts integer sequences to vector sequences\n",
        "        self.embedding = nn.Embedding(vocab_size,embedding_dim)\n",
        "        \n",
        "        # LSTM layer process the vector sequences \n",
        "        self.lstm = nn.LSTM(embedding_dim,\n",
        "                            hidden_dim,\n",
        "                            num_layers = n_layers,\n",
        "                            bidirectional = bidirectional,\n",
        "                            dropout = dropout,\n",
        "                            batch_first = True\n",
        "                           )\n",
        "        \n",
        "        # Dense layer to predict \n",
        "        self.fc = nn.Linear(hidden_dim * 2,output_dim)\n",
        "        # Prediction activation function\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "        \n",
        "    \n",
        "    def forward(self,text,text_lengths):\n",
        "        embedded = self.embedding(text)\n",
        "        \n",
        "        # Thanks to packing, LSTM don't see padding tokens \n",
        "        # and this makes our model better\n",
        "        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, text_lengths.cpu(),batch_first=True)\n",
        "        \n",
        "        packed_output,(hidden_state,cell_state) = self.lstm(packed_embedded)\n",
        "        \n",
        "        # Concatenating the final forward and backward hidden states\n",
        "        hidden = torch.cat((hidden_state[-2,:,:], hidden_state[-1,:,:]), dim = 1)\n",
        "        \n",
        "        dense_outputs=self.fc(hidden)\n",
        "\n",
        "        #Final activation function\n",
        "        outputs=self.sigmoid(dense_outputs)\n",
        "        \n",
        "        return outputs\n",
        "    "
      ],
      "metadata": {
        "trusted": true,
        "id": "fw-8NjtLLnSA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Our model class is ready, let's declare hyperparameters"
      ],
      "metadata": {
        "id": "JF3VCVGPLnSB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SIZE_OF_VOCAB = len(TEXT.vocab)\n",
        "EMBEDDING_DIM = 100\n",
        "NUM_HIDDEN_NODES = 64\n",
        "NUM_OUTPUT_NODES = 1\n",
        "NUM_LAYERS = 2\n",
        "BIDIRECTION = True\n",
        "DROPOUT = 0.2"
      ],
      "metadata": {
        "trusted": true,
        "id": "I5HwHl-CLnSB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training\n",
        "Now let's create our model instance, optimizer and loss function"
      ],
      "metadata": {
        "id": "G1Eh6JQrLnSB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = LSTMNet(SIZE_OF_VOCAB,\n",
        "                EMBEDDING_DIM,\n",
        "                NUM_HIDDEN_NODES,\n",
        "                NUM_OUTPUT_NODES,\n",
        "                NUM_LAYERS,\n",
        "                BIDIRECTION,\n",
        "                DROPOUT\n",
        "               )"
      ],
      "metadata": {
        "trusted": true,
        "id": "GD8BKRWaLnSB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "model = model.to(device)\n",
        "optimizer = optim.Adam(model.parameters(),lr=1e-4)\n",
        "criterion = nn.BCELoss()\n",
        "criterion = criterion.to(device)"
      ],
      "metadata": {
        "trusted": true,
        "id": "aOh47YEnLnSB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "trusted": true,
        "id": "ZMZ1rh7KLnSB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We'll use this helper to compute accuracy\n",
        "def binary_accuracy(preds, y):\n",
        "    #round predictions to the closest integer\n",
        "    rounded_preds = torch.round(preds)\n",
        "    \n",
        "    correct = (rounded_preds == y).float() \n",
        "    acc = correct.sum() / len(correct)\n",
        "    return acc"
      ],
      "metadata": {
        "trusted": true,
        "id": "I10aB6iVLnSC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model,iterator,optimizer,criterion):\n",
        "    \n",
        "    epoch_loss = 0.0\n",
        "    epoch_acc = 0.0\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    for batch in iterator:\n",
        "        \n",
        "        # cleaning the cache of optimizer\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        text,text_lengths = batch.text\n",
        "        \n",
        "        # forward propagation and squeezing\n",
        "        predictions = model(text,text_lengths).squeeze()\n",
        "        \n",
        "        # computing loss / backward propagation\n",
        "        loss = criterion(predictions,batch.type)\n",
        "        loss.backward()\n",
        "        \n",
        "        # accuracy\n",
        "        acc = binary_accuracy(predictions,batch.type)\n",
        "        \n",
        "        # updating params\n",
        "        optimizer.step()\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc += acc.item()\n",
        "        \n",
        "    # It'll return the means of loss and accuracy\n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n",
        "        "
      ],
      "metadata": {
        "trusted": true,
        "id": "77UCaE-wLnSC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Also we need a function to evaluate model"
      ],
      "metadata": {
        "id": "C5We_tGNLnSC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model,iterator,criterion):\n",
        "    \n",
        "    epoch_loss = 0.0\n",
        "    epoch_acc = 0.0\n",
        "    \n",
        "    # deactivate the dropouts\n",
        "    model.eval()\n",
        "    \n",
        "    # Sets require_grad flat False\n",
        "    with torch.no_grad():\n",
        "        for batch in iterator:\n",
        "            text,text_lengths = batch.text\n",
        "            \n",
        "            predictions = model(text,text_lengths).squeeze()\n",
        "              \n",
        "            #compute loss and accuracy\n",
        "            loss = criterion(predictions, batch.type)\n",
        "            acc = binary_accuracy(predictions, batch.type)\n",
        "            \n",
        "            #keep track of loss and accuracy\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "metadata": {
        "trusted": true,
        "id": "bQ4gGqJdLnSC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Let's train the model"
      ],
      "metadata": {
        "id": "Nr8a6ypSLnSC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCH_NUMBER = 15\n",
        "for epoch in range(1,EPOCH_NUMBER+1):\n",
        "    \n",
        "    train_loss,train_acc = train(model,train_iterator,optimizer,criterion)\n",
        "    \n",
        "    valid_loss,valid_acc = evaluate(model,validation_iterator,criterion)\n",
        "    \n",
        "    # Showing statistics\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')\n",
        "    print()"
      ],
      "metadata": {
        "trusted": true,
        "id": "nBZIXPInLnSC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conclusion\n",
        "It's real fun to work with Pytorch. I dont't know why but, using and learning Pytorch after Keras API, using a lower-level API and seeing how the things work in deep learning is awesome.\n",
        "\n",
        "Thanks for your attention. I'm waiting for your upvotes&questions.\n"
      ],
      "metadata": {
        "id": "z2aZPUTdLnSC"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eB9KLzThLnSD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}